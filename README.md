# A cross-cultural study about cross-modal perceptions

This repository hosts the code for a survey to collect data on cross-modal perceptions across different cultures. The survey is designed to gather insights into how people from various cultural backgrounds perceive and interpret sensory information, such as visual and auditory stimuli.

## Aknowledgments

This project extends the work started in the paper *A Multimodal Symphony: Integrating Taste and Sound through Generative AI* by Spanio, Zampini, Rodà and Pierucci.

In addition to the authors of the paper, we would like to acknowledge the contributions of the following individuals:

- **Dr. Bruno Mesz**, professor and researcher at Universidad Nacional de Tres de Febrero (Argentina)
- **Dr. Masaki Ono**, postdoctoral researcher at the Ritsumeikan University (Japan)
- **Dr. Riccardo Migliavada**, research associate at Università delle Scienze Gastronomiche di Pollenzo
- **Dr. Luisa Torri**, full professor at Università delle Scienze Gastronomiche di Pollenzo

## How to cite

If you refer this survey in your research, please cite the following paper:

```
@article{spanio_frontiers_2025,
  language = {en},
  author = {Spanio, Matteo and Zampini, Massimiliano and Rodà, Antonio and Pierucci, Franco},
  title = {A multimodal symphony: integrating taste and sound through generative AI},
  journal = {Frontiers in Computer Science},
  volume = {Volume 7 - 2025},
  year = {2025},
  url = {https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2025.1575741},
  doi = {10.3389/fcomp.2025.1575741},
  issn = {2624-9898}
}
```

## License

This repository is licensed under the [CC BY-NC-SA 4.0 License](https://creativecommons.org/licenses/by-nc-sa/4.0/). You are free to share and adapt the material for non-commercial purposes, provided you give appropriate credit, indicate if changes were made, and distribute your contributions under the same license.
